{"title":"Лабораторна робота № 2","markdown":{"yaml":{"title":"Лабораторна робота № 2"},"headingText":"Теоретичні відомості","containsRefs":false,"markdown":"\n\n\n\n\n**Тема.** Використання рекурентного аналізу для моделювання і прогнозування \nнелінійних динамічних властивостей складних систем.\n\n**Мета.** Навчитися інструментарію нелінійної динаміки, який відноситься до \nрекурентних властивостей нестаціонарних динамічних рядів. \n\n\n\n\nДослідження складних систем, як природних, так і штучних, показали, що в їх основі лежать нелінійні процеси, ретельне вивчення яких необхідне для розуміння і моделювання складних систем. У останні десятиліття набір традиційних (лінійних) методик дослідження був істотно розширений нелінійними методами, одержаними з теорії нелінійної динаміки і хаосу; багато досліджень були присвячені оцінці нелінійних характеристик і властивостей процесів, що протікають в природі (скейлінг, фрактальна розмірність). Проте більшість методів нелінійного аналізу вимагає або достатньо довгих, або стаціонарних рядів даних, які досить важко одержати з природи. Більш того, було показано, що дані методи дають задовільні результати для моделей реальних систем, що ідеалізуються. Ці чинники вимагали розробки нових методик нелінійного аналізу даних.\n\nСтан природних або штучних систем, як правило, змінюється в часі. Вивчення цих, часто складних, процесів --- важлива задача в багатьох дисциплінах, дозволяє зрозуміти і описати їх суть, наприклад, для прогнозування стану на деякий час в майбутнє. Метою таких досліджень є знаходження математичних моделей, які б достатньо відповідали реальним процесам і могли б бути використані для розв’язання поставлених задач.\n\nРозглянемо ідею і коротко теорію рекурентного аналізу, наведемо деякі приклади, розглянемо його можливі області застосування при аналізі і прогнозування складних фінансово-економічних систем. \n\n### Фазовий простір та його реконструкція\n\nСтан системи описується її змінними стану\n\n$$\nx^1(t),x^2(t),...,x^d(t)\n$$\n\nде верхній індекс --- номер змінної. Набір із $d$ змінних стану у момент часу $t$ складає вектор стану $\\vec x(t)$ в $d$-вимірному фазовому просторі. Даний вектор переміщається в часі в напрямі,визначуваному його вектором швидкості:\n\n$$\n\\dot{\\vec x}(t)=\\partial_t\\vec x(t)=\\vec F(t)\n$$\n\nПослідовність векторів $\\vec x(t)$ утворює траєкторію у фазовому просторі, причому поле швидкості $\\vec F$ дотичне до цієї траєкторії. Еволюція траєкторії описує динаміку системи і її атрактор. Знаючи $\\vec F$, можна одержати інформацію про стан системи в момент $t$ шляхом інтегрування виразу. Оскільки форма траєкторії дозволяє судити про характер процесу (періодичні або хаотичні процеси мають характерні фазові портрети), то для визначення стану системи не обов'язково проводити інтегрування, достатньо побудувати графічне відображення траєкторії.\n\nПри дослідженні складних систем часто немає інформації про всі змінні стану, або не все з них можливо виміряти. Як правило, є єдине спостереження, проведене через дискретний часовий інтервал $\\Delta t$. Таким чином, вимірювання записуються у вигляді ряду $u_i(t)$ i , де $t=i\\cdot \\Delta t$. Інтервал $\\Delta t$ може бути постійним, проте це не завжди можливо і створює проблеми для застосування стандартних методів аналізу даних, що вимагають рівномірної шкали спостережень.\n\nВзаємодії і їх кількість в складних системах такі, що навіть по одній змінній стану можна судити про динаміку всієї системи в цілому (даний факт був встановлений групою американських учених при вивченні турбулентності). Таким чином, еквівалентна фазова траєкторія, що зберігає структури оригінальної фазової траєкторії, може бути відновлена з одного спостереження або часового ряду за теоремою Такенса (Takens) методом часових затримок:\n\n$$\n\\widehat{\\vec x}(t)=(u_i,u_{i+\\tau},...,u_{i+(m-1)\\tau})\n$$\n\nде $m$ --- розмірність вкладення, $\\tau$ --- часова затримка (реальна часова затримка визначається як $\\tau \\cdot \\Delta t$). Топологічні структури відновленої траєкторії зберігаються, якщо $m \\geq 2 \\cdot d+1$, де $d$ --- розмірність атрактора. На практиці більшості випадків атрактор може бути відновлений і при $m \\leq 2d$. Затримка, як правило, вибирається апріорно.\n\nІснує кілька підходів до вибору мінімально достатньої розмірності $m$, крім аналітичного. Високу ефективність показали методи, засновані на концепції фальшивих найближчих точок (false nearest neighbours, FNN). Суть її заключається у тому, що при зменшенні розмірності вкладення відбувається збільшення кількості фальшивих точок, що потрапляють в околицю будь-якої точки фазового простору. Звідси витікає простий метод --- визначення кількості FNN як функції від розмірності. Існують і інші методи, засновані на цій концепції --- наприклад, визначення відносин відстаней між одними і тими ж сусідніми точками при різних $m$. Розмірність атрактора також може бути визначена за допомогою крос-кореляційних сум. \n\n::: {#fig-recurrence layout-ncol=2\"}\n\n![](Images\\lab_2\\2_1.jpg){width=45%}\n![](Images\\lab_2\\2_2.jpg){width=45%}\n\nВідрізок траєкторії у фазовому просторі системи Рьослера $i$ (a); відповідний рекурентний графік (b). Вектор фазового простору в точці $j$, який потрапляє в околицю (сіре коло в (a)) заданого вектора фазового простору вектора в точці $i$ вважається точкою рекурентності (чорна точка на траєкторії в (a)). Вона позначається чорною точкою на рекурентній діаграмі у позиції $(i, j)$. Вектор фазового простору за межами околу (порожнє коло в (a)) призводить до білої точки в рекурентній діаграмі\n\n:::\n\n### Рекурентний аналіз\n\nПроцесам в природі властива яскраво виражена рекурентна поведінка, така, як періодичність або іррегулярна циклічність. Більш того, рекурентність (повторюваність) станів в значенні проходження подальшої траєкторії достатньо близько до попередньої є фундаментальною властивістю дисипативних динамічних систем. Ця властивість була відмічена ще в 80-х роках XIX століття французьким математиком Пуанкаре (Poincare) і згодом сформульовано у вигляді \"теореми рекурентності\", опублікованої в 1890 р.:\n\n:::{.callout-note}\n## Примітка\n\n**Якщо система зводить свою динаміку до обмеженої підмножини фазового простору, то система майже напевно, тобто з вірогідністю, практично рівною 1, скільки завгодно близько повертається до якого-небудь спочатку заданого режиму.**\n:::\n\nСуть цієї фундаментальної властивості у тому, що, не дивлячись на те, що навіть саме мале збурення в складній динамічній системі може привести систему до експоненціального відхилення від її стану, через деякий час система прагне повернутися до стану, деяким чином близького до попереднього, і проходить при цьому подібні етапи еволюції.\n\nПереконатися в цьому можна за допомогою графічного зображення траєкторії системи у фазовому просторі. Проте можливості такого аналізу сильно обмежені. Як правило, розмірність фазового простору складної динамічної системи більша трьох, що\nробить практично незручним його розгляд напряму; єдина можливість --- проекції в дво- і тривимірні простори, що часто не дає вірного уявлення про фазовий портрет.\n\nУ 1987 р. Екман (Eckmann) і співавтори запропонували спосіб відображення $m$-вимірної фазової траєкторії станів системи $\\vec x(t)$ завдовжки $N$ на двовимірну квадратну двійкову матрицю розміром $N \\times N$ , в якій 1 (чорна точка) відповідає повторенню стану при деякому часі $i$ в деякий інший час $j$, а обидві координатні осі є осями часу. Таке представлення було назване рекурентною картою або діаграмою (recurrence plot, RP), оскільки воно фіксує інформацію про рекурентну поведінку системи.\n\nМатематично вищесказане описується як\n\n$$\nR_{i,j}^{m,\\varepsilon_i}=\\Theta(\\varepsilon_i-\\| \\vec x_i - \\vec x_j \\|), \\cdot \\vec x \\in \\Re^m, \\cdot i, j=1...N\n$$\n\nде $N$ --- кількість даних станів, $x_i, \\varepsilon_i$ --- розмір околиці точки $\\vec x$ у момент $i$, $\\| \\cdot \\|$ --- норма і $\\Theta(\\cdot)$ --- функція Хевісайда.\n\nНепрактично і, як правило, неможливо знайти повну рекурентність у значенні $\\vec x_i \\equiv \\vec x_j$ (стан динамічної, а особливо --- хаотичної системи не повторюється повністю еквівалентно початковому стану, а підходить до нього скільки завгодно близько). Таким чином, рекурентність визначається як достатня близькість стану $\\vec x_j$ до стану $\\vec x_i$. Іншими словами, рекурентними є стани $\\vec x_j$, які потрапляють в $m$-вимірну околицю з радіусом $\\varepsilon_i$ і центром в $\\vec x_i$. Ці точки $\\vec x_j$ називаються **рекурентними точками** (recurrence points).\n\nОскільки $R_{i,i}=1$, $i=1,...,N$ за визначенням, то рекурентна діаграма завжди міститьчорну діагональну лінію --- лінію ідентичності (line of identity, LOI) під кутом $\\pi/4$ до осей координат. Довільно узята рекурентна точка не несе якої-небудь корисної інформації про стани в часи $i$ і $j$. Тільки вся сукупність рекурентних точок дозволяє відновити властивості системи.\n\nЗовнішній вигляд рекурентної діаграми дозволяє судити про характер процесів, які протікають в системі, наявності і впливі шуму, станів повторення і завмирання (ламінарності), здійсненні в ході еволюції системи різких змін стану (екстремальних подій).\n\n::: {#fig-recurrence-types layout-nrows=5}\n\n![однорідна топологія](Images\\lab_2\\2_3.jpg)\n![дрейф](Images\\lab_2\\2_4.jpg)\n![Осцилююча поведінка системи](Images\\lab_2\\2_5.jpg)\n![Контрастна топологія](Images\\lab_2\\2_6.jpg)\n![Ламінарність процесу](Images\\lab_2\\2_7.jpg)\n\nТипові динамічні ряди і їх рекурентні карти\n\n:::\n\n### Аналіз діаграм\n\nОчевидно, що процеси різної поведінки даватимуть рекурентні діаграми з різним рисунком. Таким чином, візуальна оцінка діаграм може дати уявлення про еволюцію досліджуваної траєкторії. Виділяють два основних класи структури зображення: **топологія** (*typology*), що представляється крупномасштабними структурами, і **текстура** (*texture*), *що формується дрібномасштабними структурами*.\n\nТопологія дає загальне уявлення про характер процесу. Виділяють чотири основні класи:\n\n- **однорідні** рекурентні діаграми типові для стаціонарних і автономних систем, в яких час релаксації малий у порівнянні з довжиною ряду;\n- **періодичні** структури, що повторюються (діагональні лінії, узори у шаховому порядку) відповідають різним осцилюючим системам з періодичністю в динаміці;\n- **дрейф** відповідає системам з параметрами, що поволі змінюються, що робить білими лівий верхній і правий нижній кути рекурентної діаграми;\n- **різкі зміни** в динаміці системи, рівно як і екстремальні ситуації, обумовлюють появу білих областей або смуг.\n\nРекурентні діаграми **спрощують** виявлення екстремальних і рідкісних подій.\n\n::: {#fig-recurrence-diagrams layout-ncol=4}\n\n![](Images\\lab_2\\type_of_rec_a.png){#homogeneous width=35%}\n\n![](Images\\lab_2\\type_of_rec_b.png){#periodic width=35%}\n\n![](Images\\lab_2\\type_of_rec_c.png){#drift width=35%}\n\n![](Images\\lab_2\\type_of_rec_d.png){#disrupted width=35%}\n\nХарактернi топологiї рекурентних дiаграм: (а) --- однорiдна (нормально розподiлений шум); (b) --- перiодична (генератор Ван дер Поля); (c) --- дрейф (вiдображення Iкеди з накладеною послiдовнiстю, що лiнiйно росте); (d) --- контрастнi областi або смуги (узагальнений броунiвський рух)\n\n:::\n\nДокладний розгляд рекурентних діаграм дозволяє виявити дрібномасштабні структури --- текстуру, яка складається з простих точок, діагональних, горизонтальних і вертикальних ліній. Комбінації вертикальних і горизонтальних ліній формують прямокутні кластери точок.\n\n- ***самотні***, окремо розташовані рекурентні точки з'являються в тому разі, коли відповідні стани рідкісні, або нестійкі в часі, або викликані сильною флуктуацією. При цьому вони не є ознаками випадковості або шуму;\n- ***діагональні лінії*** $R_{i+k, j+k}=1$ (при $k = 1...l$ де $l$ --- довжина діагональної лінії) з'являються у разі, коли сегмент траєкторії у фазовому просторі пролягає паралельно іншому сегменту, тобто траєкторія повторює саму себе, повертаючись в одну і ту ж область фазового простору у різний час. Довжина таких ліній визначається часом, протягом якого сегменти траєкторії залишаються паралельними; напрям (кут нахилу) ліній характеризує внутрішній час підпроцесів, відповідних даним сегментам траєкторії. Проходження ліній паралельно лінії ідентичності (під кутом $\\pi/4$ до осей координат) свідчить про однаковий напрям сегментів траєкторії, перпендикулярно --- про протилежний («відображені» сегменти), що може також бути ознакою реконструкції фазового простору з невідповідною розмірністю вкладення. Нерегулярна поява діагональних ліній є ознакою хаотичного процесу;\n* ***вертикальні (горизонтальні) лінії*** $R_{i, j+k}=1$ (при $k = 1...\\upsilon$, де $\\upsilon$ --- довжина вертикальної або горизонтальної лінії) виділяють проміжки часу, в котрі стан системи не змінюється або змінюється трохи (система як би «заморожена» на цей час), що є ознакою «ламінарних» станів.\n\n::: {#fig-recurrence-concept}\n\n![](Images\\lab_2\\recurrence_lines.png){width=50%}\n\nОсновнi концепцiї рекурентного аналiзу. Вiдображена дiаграма рекурентностi базується на часовому ряду, що було реконструйовано до 11 реконструйованих векторiв, вiд $\\vec{X}(0)$ до $\\vec{X}(10)$. Видiлено дiагональну лiнiю довжиною $d = 3$, вертикальна лiнiя довжиною $v = 3$ i бiлу вертикальну лiнiю довжиною $w = 5$\n\n:::\n\n## Хід роботи\n\nСпочатку побудуємо дво- та тривимірні фазові портрети як для модельних значень, так і для реальних. Використовуватимемо бібліотеки `neurokit2` для побудови атракторів та рекурентного аналізу.\n\n### Процедура реконструкції фазового простору\n\nДля побудови фазового портрету скористаємось методами `complexity_attractor()` та `complexity_embedding()` бібліотеки `neuralkit2`. Синтаксис `complexity_attractor()` виглядає наступним чином:\n\n**`complexity_attractor(embedded='lorenz', alpha='time', color='last_dim', shadows=True, linewidth=1, **kwargs)`**\n\n**Параметри**\n\n- **embedded** (*Union[str, np.ndarray]*) --- результат функції `complexity_embedding()`. Також може бути рядком, наприклад, `\"lorenz\"` (атрактор Лоренца) або `\"rossler\"` (атрактор Рьосслера).\n- **alpha** (*Union[str, float]*) --- прозорість ліній. Якщо `\"time\"`, то лінії будуть прозорими як функція часу (повільно).\n- **color** (*str*) --- Колір графіку. Якщо `\"last_dim\"`, буде використано останній вимір (максимум 4-й) вбудованих даних, коли розмірність більша за 2. Корисно для візуалізації глибини (для 3-вимірного вбудовування), або четвертого виміру, але працюватиме це повільно.\n- **shadows** (*bool*) --- якщо значення `True`, 2D-проекції буде додано до бокових сторін 3D-атрактора.\n- **linewidth** (*float*) --- задає товщину лінії.\n- **kwargs** --- До палітри кольорів (наприклад, `name=\"plasma\"`) або до симулятора системи Лоренца передаються додаткові аргументи ключових слів, такі як `duration` (за замовчуванням = 100), `sampling_rate` (за замовчуванням = 10), `sigma` (за замовчуванням = 10), `beta` (за замовчуванням = 8/3), `rho` (за замовчуванням = 28).\n\nЯк вже зазначалося, побудова фазового простору, на основі якого і проводитиметься рекурентний аналіз, вимагає реконструкції. Виконати реконструкції фазового простору із одновимірного часового ряду можна із використанням *методу часових затримок*. \n\nМетод часових затримок є однією з ключових концепцій науки про складність, що ми використовуватимемо і в подальших лабораторних. Він базується на ідеї, що динамічна система може бути описана вектором чисел, який називається її \"станом\", що має на меті забезпечити повний опис системи в певний момент часу. Множина всіх можливих станів називається \"простором станів\".\n\nТеорема Такенса (1981) припускає, що послідовність вимірювань динамічної системи містить у собі всю інформацію, необхідну для повної реконструкції простору станів. Метод часових затримок намагається визначити стан $s$ системи в певний момент часу $t$, шукаючи в минулій історії спостережень схожі стани, і, вивчаючи еволюцію схожих станів, виводити інформацію про майбутнє системи.\n\nЯк візуалізувати динаміку системи? Послідовність значень стану в часі називається траєкторією. Залежно від системи, різні траєкторії можуть еволюціонувати до спільної підмножини простору станів, яка називається атрактором. Наявність та поведінка атракторів дає інтуїтивне уявлення про досліджувану динамічну систему.\n\nОдже, згідно Такенсу, ідея полягає в тому, щоб на основі одиничних вимірювань системи, отримати $m$-розмірні реконструйовані часові вкладення\n\n$$\n\\vec{y}_i = \\left( y_i, y_{i+\\tau}, ... , y_{i+(m-1)\\tau} \\right),\n$$ {#eq-2-1}\n\nде $i$ проходить в діапазоні $1,..., N-(m-1)\\tau$; значення $\\tau$ представляє часову затримку, а $m$ --- це розмірність вкладень (кількість змінних, що включає кожна траєкторія).\n\nКод для реконструкції фазового простору може виглядати наступним чином:\n\nДля реконструкції фазового простору використовуватимемо метод `complexity_embedding()`. Його синтаксис виглядає наступним чином:\n\n**`complexity_embedding(signal, delay=1, dimension=3, show=False, **kwargs)`**\n\n**Параметри**\n\n- **signal** (*Union[list, np.array, pd.Series]*) --- сигнал (тобто часовий ряд) у вигляді вектора значень. Також може бути рядком, наприклад, `\"lorenz\"` (атрактор Лоренца), `\"rossler\"` (атрактор Росслера) або `\"clifford\"` (атрактор Кліффорда) для отримання попередньо визначеного атрактора.\n- **delay** (*int*) --- часова затримка (часто позначається $\\tau$ іноді називають запізненням). Ще розглянемо метод `complexity_delay()` для оцінки оптимального значення цього параметра.\n- **dimension** (*int*) --- розмірність вкладень ($m$, іноді позначається як $d$ або порядок). Далі звернемось до методу `complexity_dimension()`, щоб оцінити оптимальне значення для цього параметра.\n- **show** (*bool*) --- Побудувати графік реконструйованого атрактора.\n- **kwargs** --- інші аргументи, що передаються до `complexity_attractor()`.\n\n**Повертає**\n\n- *array* --- реконструйований атрактор розміру `length - (dimension - 1) * delay`\n\n\n\nДалі імпортуємо необхідні для подальшої роботи модулі\n\nІ виконаємо налаштування рисунків для виводу\n\nТепер розглянемо можливість використання методу часових затримок і отриманих в подальшому атракторів у якості індикатора складності. Як і в попередній роботі, для прикладу завантажимо часовий ряд Біткоїна за період з 1 вересня 2015 по 1 березня 2020, використовуючи `yfinance`:\n\n::: {.callout-warning}\n## Увага\n\nВиконайте цей блок, якщо хочете зчитати дані не з Yahoo! Finance, а з власного файлу\n\n:::\n\n---\n\n---\n\nСпочатку оберемо вид ряду:\n1. вихідний ряд\n2. детермінований (різниця між теперішнім та попереднім значенням)\n3. прибутковості звичайні\n4. стандартизовані прибутковості\n5. абсолютні значення (волатильності)\n6. стандартизований ряд\n\nДля подальших розрахунків накращим варіантом буде вибір стандартизованого вихідного ряду або прибутковостей, оскільки значення вихідного часового ряду відрізняються на декілька порядків, і можуть сильно перевищувати встановлений параметр $\\varepsilon$. Тобто, для вихідних значень, що сильно різняться між собою, увесь часовий діапазон буде розглядатися як нерекурентний.\n\nСпочатку визначимо функції для виконання перетворення ряду:\n\nі тепер виконаємо перетворення, використовуючи дану функцію:\n\nОскільки ми не матимемо змоги візуалізувати багатовимірний фазовий простір ($m>3$), ми послуговуватимемось значеннями $m=2$ та $m=3$. Значення $\\tau$ будемо варіювати як із власних переконань, так і з опорою на функціонал бібліотеки `neuralkit2`. \n\nСкористаємось методом `complexity_simulate()` для генерації різних тестових сигналів. \n\nУ зазначених вище прикладах прикладах ми обирали параметри $m$ і $\\tau$ згідно нашим власним міркуванням. Але, як правило, при виконанні серйозного дослідження, що матиме прикладне застосування, лише власних переконань буває недостатньо. У нашому випадку бажано було б, щоб зазначені параметри обирались автоматично, опираючись на конкретну статистичну процедуру. Бібліотека `neurokit2` представляє функціонал для автоматичного підбору параметрів розмірності та часової затримки. Коротко їх опишемо. \n\n### Автоматизований підбір параметра часової затримки, $\\tau$\n\nЧасова затримка (*Tau* $\\tau$ також відома як *Lag*) є одним з двох критичних параметрів, що беруть участь у процедурі реконструкції фазового простору. Він відповідає затримці у відліках між вихідним сигналом і його затриманою версією (версіями). Іншими словами, скільки відліків ми розглядаємо між певним станом сигналу та його найближчим минулим станом.\n\nЯкщо $\\tau$ менше оптимального теоретичного значення, послідовні координати стану системи корельовані і атрактор недостатньо розгорнутий. І навпаки, коли $\\tau$ більше, ніж повинно бути, послідовні координати майже незалежні, що призводить до некорельованої та неструктурованої хмари точок.\n\nВибір параметрів *затримки* та *розмірності* представляє нетривіальну задачу. Один з підходів полягає у їх (напів)незалежному виборі (оскільки вибір розмірності часто вимагає затримки) за допомогою функцій `complexity_delay()` та `complexity_dimension()`. Однак, існують методи спільного оцінювання, які намагаються знайти оптимальну затримку та розмірність одночасно.\n\nЗауважте також, що деякі автори (наприклад, Розенштейн, 1994) пропонують спочатку визначити оптимальну розмірність вбудовування, а потім розглядати оптимальне значення затримки як оптимальну затримку між першою та останньою координатами затримки (іншими словами, фактична затримка має дорівнювати оптимальній затримці, поділеній на оптимальну розмірність вбудовування мінус 1).\n\nДекілька авторів запропонували різні методи для вибору затримки:\n\n- **Фрейзер і Свінні (1986)** пропонують використовувати перший локальний мінімум взаємної інформації між затриманим і незатриманим часовими рядами, ефективно визначаючи значення $\\tau$, для якого вони діляться найменшою інформацією (і де атрактор є найменш надлишковим). На відміну від автокореляції, взаємна інформація враховує також нелінійні кореляції.\n- **Тейлер (1990)** запропонував вибирати таке значення $\\tau$, при якому автокореляція між сигналом та його зміщенною версією при $\\tau$ вперше перетинає значення $1/\\exp$. Методи, що базуються на автокореляції, мають перевагу в короткому часі обчислень, коли вони обчислюються за допомогою алгоритму швидкого перетворення Фур'є (fast Fourier transform, FFT).\n- **Касдаглі (1991)** пропонує замість цього брати перший нульовий перетин автокореляції.\n- **Розенштейн (1993)** пропонує апроксимувати точку, де функція автокореляцій падає до $\\left( 1-1/\\exp \\right)$ від свого максимального значення.\n- **Розенштейн (1994)** пропонує наближатися до точки, близької до 40% нахилу середнього зміщення від діагоналі.\n- **Кім (1999)** пропонує оцінювати Tau за допомогою кореляційного інтегралу, який називається C-C методом, і який, як виявилося, узгоджується з результатами, отриманими за допомогою методу взаємної інформації. Цей метод використовує статистику в реконструйованому фазовому просторі, а не аналізує часову еволюцію ряду. Однак час обчислень для цього методу значно довший через необхідність порівнювати кожну унікальну пару парних векторів у реконструйованому сигналі на кожну затримку.\n- **Лайл (2021)** описує \"Реконструкцію симетричного проекційного атрактора\" (Symmetric Projection Attractor Reconstruction, SPAR), де $1/3$ від домінуючої частоти (тобто довжини середнього \"циклу\") може бути підходящим значенням для приблизно періодичних даних, і робить атрактор чутливим до морфологічних змін. Див. також [доповідь Астона](https://youtu.be/GGrOJtcTcHA?t=730). Цей метод також є найшвидшим, але може не підходити для аперіодичних сигналів. Аргумент `algorithm` (за замовчуванням `\"fft\"`) передається до аргументу `method` методу [`signal_psd()`](https://neuropsychology.github.io/NeuroKit/functions/signal.html#signal-psd).\n\nМожна також зазначити наступний метод для об'єднаного підбору параметрів затримки та розмірності:\n\n- **Гаутама (2003)** зазначає, що на практиці часто використовують фіксовану часову затримку і відповідно регулюють розмірність вбудовування. Оскільки це може призвести до великих значень $m$ (а отже, до вкладених даних великого розміру) і, відповідно, до повільної обробки, вони описують метод оптимізації для спільного визначення $m$ і $\\tau$ на основі показника **entropy ratio**.\n\nРозглянемо оптимальні значення розмірності та затримки для часового сигналу Біткоїна:\n\n@fig-btc-delay-fraser1986 показує, що перший локальний мінімум взаємної інформації для стандартизованих вихідних значень Біткоїна знаходиться на 273 лагу. Для візуального огляду реконструйованого атрактора це значення, можливо, є найбільш адекватним. Але використовуючи настільки велику часову затримку, ми втрачаємо доволі багато проміжних значень, що також можуть містити досить важливу приховану інформацію для кількісних розрахунків. \n\n@fig-btc-delay-theiler демонструє, що автокореляція між стандартизованих вихідним сигналом Біткоїна та його зміщенною версією при $\\tau=195$ вперше перетинає значення $1/\\exp$. Бачимо, що дане значення затримки є трохи меншим за те, що було отримано до цього, але суті це не змінює. Також бачимо, що між реконструйованими атракторами для $\\tau=195$ та $\\tau=273$ немає кардинальної візуальної різниці. \n\nЯк можна бачити по прикладу вище, не всі методи надають адекватну оцінку розмірності нашого сигналу. Спробуємо привести вихідні значення Біткоїна до прибутковостей та повторити процедуру Касдаглі ще раз.  \n\nЦього разу нам вдалося досягти оптимального результату, але приклад вище демонструє, що кожна процедура має свої виключення. @fig-btc-delay-casdagli1991 показує, що значення прибутковостей Біткоїна характеризуються певними кореляціями лише на перших 4-ох лагах. Подальші часові зміщення роблять значення прибутковостей незалежними один від одного.\n\n@fig-btc-delay-rosenstein1993 демонструє, що при $\\tau=101$ функція автокореляцій перетинає значення $\\left( 1-1/\\exp \\right)$. При цьому видно, що навіть для такого лагу зберігається значна частка кореляцій між стандартизованими вихідними значеннями Біткоїна. \n\nРисунок вище показує, що при $\\tau=120$ зміщення реконструйованих траєкторій від їх оригінального положення на лінії ідентичності зберігає найбільшу кількість інформації стосовно атрактора стандартизованих значень Біткоїна. \n\nЗгідно представленого вище результату найбільш значущі частоти, отримані за допомогою перетворення Фур'є, зберігаються при $\\tau=109$. \n\nТепер подивимось як це виглядатиме для об'єднаного підбору параметрів\n\nОскільки представлена вище процедура є доволі громіздкою в плані обчислювальних потужностей, ми обрали діапазон $\\tau$ в межах від 1 до 30. Видно, що при $\\tau$ близької до 10 оптимальне значення розмірності атрактора дорівнює 20. Можливо, при значеннях $\\tau$ близьких до 100 або 200, ми могли б отримати зовсім інше значення розмірності, але це потребує додаткових експериментів. \n\n### Автоматизований підбір параметра розмірності вкладень, $m$\n\nЗа дану процедуру відповідає метод `complexity dimension()`. Її синтаксис виглядає наступним чином:\n\n**`complexity_dimension(signal, delay=1, dimension_max=20, method='afnn', show=False, **kwargs)`**\n\nХоча зазвичай використовують $m=2$ або $m=3$, але різні автори пропонують наступні процедури підбору:\n\n- **Кореляційна розмірність (Correlation Dimension, CD)**: Одним з перших методів оцінки оптимального $m$ був розрахунок кореляційної розмірності для вкладень різного розміру і пошук насичення (тобто плато) в її значенні при збільшенні розміру векторів. Одне з обмежень полягає в тому, що насичення буде також мати місце, коли даних недостатньо для адекватного заповнення простору високої розмірності (зауважте, що в загальному випадку не рекомендується мати настільки великі вкладення, оскільки це значно скорочує довжину сигналу).\n- **Найближчі хибні сусіди (False Nearest Neighbour, FNN)**: Метод, запропонований Кеннелом та ін., базується на припущенні, що дві точки, які є близькими одна до одної в достатній розмірності вбудовування, повинні залишатися близькими при збільшенні розмірності. Алгоритм перевіряє сусідів при збільшенні розмірності вкладень, поки не знайде лише незначну кількість хибних сусідів при переході від розмірності $m$ до $m+1$. Це відповідає найнижчій розмірності вкладення, яка, як передбачається, дає розгорнуту реконструкцію просторово-часового стану. Цей метод може не спрацювати в зашумлених сигналах через марну спробу розгорнути шум (а в чисто випадкових сигналах кількість хибних сусідів суттєво не зменшується зі збільшенням $m$). На рисунку нижче показано, як проекції на простори більшої розмірності можна використовувати для виявлення хибних найближчих сусідів. Наприклад, червона та жовта точки є сусідами в одновимірному просторі, але не в двовимірному.\n\n![](Images\\lab_2\\douglas2022b.png){width=30% fig-align=\"center\" fig-alt=\"Проєкція траєкторій до різних розмірностей\"}\n\n- **Середні хибні сусіди (Average False Neighbors, AFN)**: Ця модифікація методу FNN, розроблена Сао (1997), усуває один з його основних недоліків --- необхідність евристичного вибору порогових значень $r$. Метод використовує максимальну евклідову відстань для представлення найближчих сусідів і усереднює всі відношення відстані в $m+1$ розмірності до розмірності $m$ і визначає *E1* та *E2* як параметри. Оптимальна розмірність відповідає досягається тоді, коли *E1* перестає змінюватися (досягає плато). *E1* досягає плато при розмірності *d0*, якщо сигнал надходить від атрактора. Тоді *d0*+1* є оптимальною мінімальною розмірністю вкладення. *E2* є корисною величиною для того, щоб відрізнити детерміновані сигнали від стохастичних. Константа *E2*, що близька до 1 для будь-якої розмірності вкладень $d$, вказує на випадковість даних, оскільки майбутні значення не залежать від минулих значень.\n\n**Параметри**\n\n- **signal** (*Union[list, np.array, pd.Series]*) --- сигнал (тобто часовий ряд) у вигляді вектора значень.\n- **delay** (*int*) --- часова затримка у відліках. Для вибору оптимального значення цього параметра ми ще скористаємось методом `complexity_delay()`.\n- **dimension_max** (*int*) --- максимальний розмір вкладення для тестування.\n- **method** (*str*) --- Може бути `\"afn\"` (середні хибні сусіди), `\"fnn\"` (найближчий хибний сусід) або `\"cd\"` (кореляційна розмірність).\n- **show** (*bool*) --- Візуалізувати результат.\n- **kwargs** --- інші аргументи, такі як $R=10.0$ або $A=2.0$ (відносне та абсолютне граничне значення, тільки для методу `\"fnn\"`).\n\n**Повертає**\n\n- **dimension** (*int*) --- оптимальна розмірність вкладень.\n- **parameters** (*dict*) --- словник python, що містить додаткову інформацію про параметри, які використовуються для обчислення оптимальної розмірності.\n\nСпробуємо отримати оптимальне значення розмірності згідно зазначених процедур. В якості часової затримки можна взять $\\tau=100$. Приблизно таке значення спостерігалося для кожної процедури. \n\n@fig-btc-dim-cd представляє, що оптимальна розмірність вкладень при якій досягається найбільш інформативна репрезентація фазового простору дорівнює 7.  \n\nЗ представленого вище рисунку видно, що найнижча розмірності вкладення, яка, як передбачається, дає розгорнуту реконструкцію просторово-часового стану, дорівнює 3. Саме при переході від 3-ох вимірного фазового простору до 4-ох вимірного ми бачимо, що кількість хибних сусідів стає мінімальною і далі не наростає. \n\nАлгоритм середніх хибних сусідів показує, що тут розмірність вкладень $m=5$ є найоптимальнішою. При подальшому наростанні розмірності, атрактор має походити на більш стохастичний, що вказує на втрату всіх кореляцій, що могли бути присутні в досліджуваному сигналі.  \n\nЗгідно з представленими вище алгоритмами автоматичного підбору, розмірність вкладень можна обирати в діапазоні значень від 3 до 7. Тепер на основі отриманих результатів приступимо до побудови рекурентної діаграми. \n\n### Побудова рекурентної матриці\n\nЯк вже зазначалося, рекурентний аналіз кількісно визначає кількість і тривалість рекурентних станів динамічної системи, що визначаються на основі реконструйованих траєкторій фазового простору. \n\nМи маємо змогу побудувати рекурентну матрицю, використовуючи метод `recurrence_matrix()`. \n\nЙого синтаксис виглядає наступним чином:\n\n**`recurrence_matrix(signal, delay=1, dimension=3, tolerance='default', show=False)`**\n\n**Параметри**\n\n- **signal** (*Union[list, np.ndarray, pd.Series]*) --- сигнал (тобто часовий ряд) у вигляді вектора значень.\n- **delay** (*int*) --- затримка в часі. \n- **dimension** (*int*) --- розмірність вкладень, $m$. \n- **tolerance** (*float*) --- радіус $\\varepsilon$ багатовимірного околу в межах якого шукаються рекурентні траєкторії (часто позначається як $r$), відстань, на якій дві точки даних вважаються схожими. Якщо `\"sd\"` (за замовчуванням), буде встановлено значення $0.2 \\cdot SD_{signal}$. Емпіричним правилом є встановлення $r$ таким чином, щоб відсоток точок, класифікованих як рекурентні, становив приблизно 2-5%.\n- **show** (*bool*) --- візуалізувати рекурентну матрицю.\n\n**Повертає**\n\n- *np.ndarray* --- рекурентну матрицю.\n- *np.ndarray* --- матрицю відстаней.\n\nПобудуємо рекурентну матрицю для вихідних значень Біткоїна, його прибутковостей та стандартизованого вихідного ряду. Розмірність $m=4$, часова затримка $\\tau=1$, радіус $\\varepsilon=0.3$. \n\nЯк можна бачити з представленого рисунку всі траєкторії залишаються доволі віддаленими один від одного, ніякої рекурентності тут не передбачається. \n\nТепер спробуємо подивитися на стандартизовані прибутковості.\n\nТепер можемо бачити, що Біткоїн став характризуватися чорними смугами, що відображають динаміку певних детермінованих процесів. У той же час білі смуги характеризують періоди абсолютно аномальної (непередбачуваної поведінки на даному ринку). Видно, що прибутковості залишаються доволі некорельованими, про що і свідчить переважне домінування саме білих областей.\n\nСпробуємо тепер подивитись на стандартизований вихідний ряд.\n\nНа початку свого існування Біткоїн характеризувався доволі високим ступенем передбачуваності, меншої волатильності власних коливань. Надалі почали предомінувати білі області, але видно, що тепер Біткоїну властива динаміка подібна до броунівсього руху. \n\n## Завдання для самостійної роботи\n\n1. Отримати індекс часового ряду у викладача\n2. Провести дослідження його рекурентних властивостей згідно інструкції\n3. Порівняти фазові портрети і рекурентні діаграми для стандартизованого вихідного ряду та прибутковостей. Що спільного між ними і чим вони відрізняються?\n4. Зробити висновки\n","srcMarkdownNoYaml":"\n\n\n\n\n**Тема.** Використання рекурентного аналізу для моделювання і прогнозування \nнелінійних динамічних властивостей складних систем.\n\n**Мета.** Навчитися інструментарію нелінійної динаміки, який відноситься до \nрекурентних властивостей нестаціонарних динамічних рядів. \n\n\n\n## Теоретичні відомості\n\nДослідження складних систем, як природних, так і штучних, показали, що в їх основі лежать нелінійні процеси, ретельне вивчення яких необхідне для розуміння і моделювання складних систем. У останні десятиліття набір традиційних (лінійних) методик дослідження був істотно розширений нелінійними методами, одержаними з теорії нелінійної динаміки і хаосу; багато досліджень були присвячені оцінці нелінійних характеристик і властивостей процесів, що протікають в природі (скейлінг, фрактальна розмірність). Проте більшість методів нелінійного аналізу вимагає або достатньо довгих, або стаціонарних рядів даних, які досить важко одержати з природи. Більш того, було показано, що дані методи дають задовільні результати для моделей реальних систем, що ідеалізуються. Ці чинники вимагали розробки нових методик нелінійного аналізу даних.\n\nСтан природних або штучних систем, як правило, змінюється в часі. Вивчення цих, часто складних, процесів --- важлива задача в багатьох дисциплінах, дозволяє зрозуміти і описати їх суть, наприклад, для прогнозування стану на деякий час в майбутнє. Метою таких досліджень є знаходження математичних моделей, які б достатньо відповідали реальним процесам і могли б бути використані для розв’язання поставлених задач.\n\nРозглянемо ідею і коротко теорію рекурентного аналізу, наведемо деякі приклади, розглянемо його можливі області застосування при аналізі і прогнозування складних фінансово-економічних систем. \n\n### Фазовий простір та його реконструкція\n\nСтан системи описується її змінними стану\n\n$$\nx^1(t),x^2(t),...,x^d(t)\n$$\n\nде верхній індекс --- номер змінної. Набір із $d$ змінних стану у момент часу $t$ складає вектор стану $\\vec x(t)$ в $d$-вимірному фазовому просторі. Даний вектор переміщається в часі в напрямі,визначуваному його вектором швидкості:\n\n$$\n\\dot{\\vec x}(t)=\\partial_t\\vec x(t)=\\vec F(t)\n$$\n\nПослідовність векторів $\\vec x(t)$ утворює траєкторію у фазовому просторі, причому поле швидкості $\\vec F$ дотичне до цієї траєкторії. Еволюція траєкторії описує динаміку системи і її атрактор. Знаючи $\\vec F$, можна одержати інформацію про стан системи в момент $t$ шляхом інтегрування виразу. Оскільки форма траєкторії дозволяє судити про характер процесу (періодичні або хаотичні процеси мають характерні фазові портрети), то для визначення стану системи не обов'язково проводити інтегрування, достатньо побудувати графічне відображення траєкторії.\n\nПри дослідженні складних систем часто немає інформації про всі змінні стану, або не все з них можливо виміряти. Як правило, є єдине спостереження, проведене через дискретний часовий інтервал $\\Delta t$. Таким чином, вимірювання записуються у вигляді ряду $u_i(t)$ i , де $t=i\\cdot \\Delta t$. Інтервал $\\Delta t$ може бути постійним, проте це не завжди можливо і створює проблеми для застосування стандартних методів аналізу даних, що вимагають рівномірної шкали спостережень.\n\nВзаємодії і їх кількість в складних системах такі, що навіть по одній змінній стану можна судити про динаміку всієї системи в цілому (даний факт був встановлений групою американських учених при вивченні турбулентності). Таким чином, еквівалентна фазова траєкторія, що зберігає структури оригінальної фазової траєкторії, може бути відновлена з одного спостереження або часового ряду за теоремою Такенса (Takens) методом часових затримок:\n\n$$\n\\widehat{\\vec x}(t)=(u_i,u_{i+\\tau},...,u_{i+(m-1)\\tau})\n$$\n\nде $m$ --- розмірність вкладення, $\\tau$ --- часова затримка (реальна часова затримка визначається як $\\tau \\cdot \\Delta t$). Топологічні структури відновленої траєкторії зберігаються, якщо $m \\geq 2 \\cdot d+1$, де $d$ --- розмірність атрактора. На практиці більшості випадків атрактор може бути відновлений і при $m \\leq 2d$. Затримка, як правило, вибирається апріорно.\n\nІснує кілька підходів до вибору мінімально достатньої розмірності $m$, крім аналітичного. Високу ефективність показали методи, засновані на концепції фальшивих найближчих точок (false nearest neighbours, FNN). Суть її заключається у тому, що при зменшенні розмірності вкладення відбувається збільшення кількості фальшивих точок, що потрапляють в околицю будь-якої точки фазового простору. Звідси витікає простий метод --- визначення кількості FNN як функції від розмірності. Існують і інші методи, засновані на цій концепції --- наприклад, визначення відносин відстаней між одними і тими ж сусідніми точками при різних $m$. Розмірність атрактора також може бути визначена за допомогою крос-кореляційних сум. \n\n::: {#fig-recurrence layout-ncol=2\"}\n\n![](Images\\lab_2\\2_1.jpg){width=45%}\n![](Images\\lab_2\\2_2.jpg){width=45%}\n\nВідрізок траєкторії у фазовому просторі системи Рьослера $i$ (a); відповідний рекурентний графік (b). Вектор фазового простору в точці $j$, який потрапляє в околицю (сіре коло в (a)) заданого вектора фазового простору вектора в точці $i$ вважається точкою рекурентності (чорна точка на траєкторії в (a)). Вона позначається чорною точкою на рекурентній діаграмі у позиції $(i, j)$. Вектор фазового простору за межами околу (порожнє коло в (a)) призводить до білої точки в рекурентній діаграмі\n\n:::\n\n### Рекурентний аналіз\n\nПроцесам в природі властива яскраво виражена рекурентна поведінка, така, як періодичність або іррегулярна циклічність. Більш того, рекурентність (повторюваність) станів в значенні проходження подальшої траєкторії достатньо близько до попередньої є фундаментальною властивістю дисипативних динамічних систем. Ця властивість була відмічена ще в 80-х роках XIX століття французьким математиком Пуанкаре (Poincare) і згодом сформульовано у вигляді \"теореми рекурентності\", опублікованої в 1890 р.:\n\n:::{.callout-note}\n## Примітка\n\n**Якщо система зводить свою динаміку до обмеженої підмножини фазового простору, то система майже напевно, тобто з вірогідністю, практично рівною 1, скільки завгодно близько повертається до якого-небудь спочатку заданого режиму.**\n:::\n\nСуть цієї фундаментальної властивості у тому, що, не дивлячись на те, що навіть саме мале збурення в складній динамічній системі може привести систему до експоненціального відхилення від її стану, через деякий час система прагне повернутися до стану, деяким чином близького до попереднього, і проходить при цьому подібні етапи еволюції.\n\nПереконатися в цьому можна за допомогою графічного зображення траєкторії системи у фазовому просторі. Проте можливості такого аналізу сильно обмежені. Як правило, розмірність фазового простору складної динамічної системи більша трьох, що\nробить практично незручним його розгляд напряму; єдина можливість --- проекції в дво- і тривимірні простори, що часто не дає вірного уявлення про фазовий портрет.\n\nУ 1987 р. Екман (Eckmann) і співавтори запропонували спосіб відображення $m$-вимірної фазової траєкторії станів системи $\\vec x(t)$ завдовжки $N$ на двовимірну квадратну двійкову матрицю розміром $N \\times N$ , в якій 1 (чорна точка) відповідає повторенню стану при деякому часі $i$ в деякий інший час $j$, а обидві координатні осі є осями часу. Таке представлення було назване рекурентною картою або діаграмою (recurrence plot, RP), оскільки воно фіксує інформацію про рекурентну поведінку системи.\n\nМатематично вищесказане описується як\n\n$$\nR_{i,j}^{m,\\varepsilon_i}=\\Theta(\\varepsilon_i-\\| \\vec x_i - \\vec x_j \\|), \\cdot \\vec x \\in \\Re^m, \\cdot i, j=1...N\n$$\n\nде $N$ --- кількість даних станів, $x_i, \\varepsilon_i$ --- розмір околиці точки $\\vec x$ у момент $i$, $\\| \\cdot \\|$ --- норма і $\\Theta(\\cdot)$ --- функція Хевісайда.\n\nНепрактично і, як правило, неможливо знайти повну рекурентність у значенні $\\vec x_i \\equiv \\vec x_j$ (стан динамічної, а особливо --- хаотичної системи не повторюється повністю еквівалентно початковому стану, а підходить до нього скільки завгодно близько). Таким чином, рекурентність визначається як достатня близькість стану $\\vec x_j$ до стану $\\vec x_i$. Іншими словами, рекурентними є стани $\\vec x_j$, які потрапляють в $m$-вимірну околицю з радіусом $\\varepsilon_i$ і центром в $\\vec x_i$. Ці точки $\\vec x_j$ називаються **рекурентними точками** (recurrence points).\n\nОскільки $R_{i,i}=1$, $i=1,...,N$ за визначенням, то рекурентна діаграма завжди міститьчорну діагональну лінію --- лінію ідентичності (line of identity, LOI) під кутом $\\pi/4$ до осей координат. Довільно узята рекурентна точка не несе якої-небудь корисної інформації про стани в часи $i$ і $j$. Тільки вся сукупність рекурентних точок дозволяє відновити властивості системи.\n\nЗовнішній вигляд рекурентної діаграми дозволяє судити про характер процесів, які протікають в системі, наявності і впливі шуму, станів повторення і завмирання (ламінарності), здійсненні в ході еволюції системи різких змін стану (екстремальних подій).\n\n::: {#fig-recurrence-types layout-nrows=5}\n\n![однорідна топологія](Images\\lab_2\\2_3.jpg)\n![дрейф](Images\\lab_2\\2_4.jpg)\n![Осцилююча поведінка системи](Images\\lab_2\\2_5.jpg)\n![Контрастна топологія](Images\\lab_2\\2_6.jpg)\n![Ламінарність процесу](Images\\lab_2\\2_7.jpg)\n\nТипові динамічні ряди і їх рекурентні карти\n\n:::\n\n### Аналіз діаграм\n\nОчевидно, що процеси різної поведінки даватимуть рекурентні діаграми з різним рисунком. Таким чином, візуальна оцінка діаграм може дати уявлення про еволюцію досліджуваної траєкторії. Виділяють два основних класи структури зображення: **топологія** (*typology*), що представляється крупномасштабними структурами, і **текстура** (*texture*), *що формується дрібномасштабними структурами*.\n\nТопологія дає загальне уявлення про характер процесу. Виділяють чотири основні класи:\n\n- **однорідні** рекурентні діаграми типові для стаціонарних і автономних систем, в яких час релаксації малий у порівнянні з довжиною ряду;\n- **періодичні** структури, що повторюються (діагональні лінії, узори у шаховому порядку) відповідають різним осцилюючим системам з періодичністю в динаміці;\n- **дрейф** відповідає системам з параметрами, що поволі змінюються, що робить білими лівий верхній і правий нижній кути рекурентної діаграми;\n- **різкі зміни** в динаміці системи, рівно як і екстремальні ситуації, обумовлюють появу білих областей або смуг.\n\nРекурентні діаграми **спрощують** виявлення екстремальних і рідкісних подій.\n\n::: {#fig-recurrence-diagrams layout-ncol=4}\n\n![](Images\\lab_2\\type_of_rec_a.png){#homogeneous width=35%}\n\n![](Images\\lab_2\\type_of_rec_b.png){#periodic width=35%}\n\n![](Images\\lab_2\\type_of_rec_c.png){#drift width=35%}\n\n![](Images\\lab_2\\type_of_rec_d.png){#disrupted width=35%}\n\nХарактернi топологiї рекурентних дiаграм: (а) --- однорiдна (нормально розподiлений шум); (b) --- перiодична (генератор Ван дер Поля); (c) --- дрейф (вiдображення Iкеди з накладеною послiдовнiстю, що лiнiйно росте); (d) --- контрастнi областi або смуги (узагальнений броунiвський рух)\n\n:::\n\nДокладний розгляд рекурентних діаграм дозволяє виявити дрібномасштабні структури --- текстуру, яка складається з простих точок, діагональних, горизонтальних і вертикальних ліній. Комбінації вертикальних і горизонтальних ліній формують прямокутні кластери точок.\n\n- ***самотні***, окремо розташовані рекурентні точки з'являються в тому разі, коли відповідні стани рідкісні, або нестійкі в часі, або викликані сильною флуктуацією. При цьому вони не є ознаками випадковості або шуму;\n- ***діагональні лінії*** $R_{i+k, j+k}=1$ (при $k = 1...l$ де $l$ --- довжина діагональної лінії) з'являються у разі, коли сегмент траєкторії у фазовому просторі пролягає паралельно іншому сегменту, тобто траєкторія повторює саму себе, повертаючись в одну і ту ж область фазового простору у різний час. Довжина таких ліній визначається часом, протягом якого сегменти траєкторії залишаються паралельними; напрям (кут нахилу) ліній характеризує внутрішній час підпроцесів, відповідних даним сегментам траєкторії. Проходження ліній паралельно лінії ідентичності (під кутом $\\pi/4$ до осей координат) свідчить про однаковий напрям сегментів траєкторії, перпендикулярно --- про протилежний («відображені» сегменти), що може також бути ознакою реконструкції фазового простору з невідповідною розмірністю вкладення. Нерегулярна поява діагональних ліній є ознакою хаотичного процесу;\n* ***вертикальні (горизонтальні) лінії*** $R_{i, j+k}=1$ (при $k = 1...\\upsilon$, де $\\upsilon$ --- довжина вертикальної або горизонтальної лінії) виділяють проміжки часу, в котрі стан системи не змінюється або змінюється трохи (система як би «заморожена» на цей час), що є ознакою «ламінарних» станів.\n\n::: {#fig-recurrence-concept}\n\n![](Images\\lab_2\\recurrence_lines.png){width=50%}\n\nОсновнi концепцiї рекурентного аналiзу. Вiдображена дiаграма рекурентностi базується на часовому ряду, що було реконструйовано до 11 реконструйованих векторiв, вiд $\\vec{X}(0)$ до $\\vec{X}(10)$. Видiлено дiагональну лiнiю довжиною $d = 3$, вертикальна лiнiя довжиною $v = 3$ i бiлу вертикальну лiнiю довжиною $w = 5$\n\n:::\n\n## Хід роботи\n\nСпочатку побудуємо дво- та тривимірні фазові портрети як для модельних значень, так і для реальних. Використовуватимемо бібліотеки `neurokit2` для побудови атракторів та рекурентного аналізу.\n\n### Процедура реконструкції фазового простору\n\nДля побудови фазового портрету скористаємось методами `complexity_attractor()` та `complexity_embedding()` бібліотеки `neuralkit2`. Синтаксис `complexity_attractor()` виглядає наступним чином:\n\n**`complexity_attractor(embedded='lorenz', alpha='time', color='last_dim', shadows=True, linewidth=1, **kwargs)`**\n\n**Параметри**\n\n- **embedded** (*Union[str, np.ndarray]*) --- результат функції `complexity_embedding()`. Також може бути рядком, наприклад, `\"lorenz\"` (атрактор Лоренца) або `\"rossler\"` (атрактор Рьосслера).\n- **alpha** (*Union[str, float]*) --- прозорість ліній. Якщо `\"time\"`, то лінії будуть прозорими як функція часу (повільно).\n- **color** (*str*) --- Колір графіку. Якщо `\"last_dim\"`, буде використано останній вимір (максимум 4-й) вбудованих даних, коли розмірність більша за 2. Корисно для візуалізації глибини (для 3-вимірного вбудовування), або четвертого виміру, але працюватиме це повільно.\n- **shadows** (*bool*) --- якщо значення `True`, 2D-проекції буде додано до бокових сторін 3D-атрактора.\n- **linewidth** (*float*) --- задає товщину лінії.\n- **kwargs** --- До палітри кольорів (наприклад, `name=\"plasma\"`) або до симулятора системи Лоренца передаються додаткові аргументи ключових слів, такі як `duration` (за замовчуванням = 100), `sampling_rate` (за замовчуванням = 10), `sigma` (за замовчуванням = 10), `beta` (за замовчуванням = 8/3), `rho` (за замовчуванням = 28).\n\nЯк вже зазначалося, побудова фазового простору, на основі якого і проводитиметься рекурентний аналіз, вимагає реконструкції. Виконати реконструкції фазового простору із одновимірного часового ряду можна із використанням *методу часових затримок*. \n\nМетод часових затримок є однією з ключових концепцій науки про складність, що ми використовуватимемо і в подальших лабораторних. Він базується на ідеї, що динамічна система може бути описана вектором чисел, який називається її \"станом\", що має на меті забезпечити повний опис системи в певний момент часу. Множина всіх можливих станів називається \"простором станів\".\n\nТеорема Такенса (1981) припускає, що послідовність вимірювань динамічної системи містить у собі всю інформацію, необхідну для повної реконструкції простору станів. Метод часових затримок намагається визначити стан $s$ системи в певний момент часу $t$, шукаючи в минулій історії спостережень схожі стани, і, вивчаючи еволюцію схожих станів, виводити інформацію про майбутнє системи.\n\nЯк візуалізувати динаміку системи? Послідовність значень стану в часі називається траєкторією. Залежно від системи, різні траєкторії можуть еволюціонувати до спільної підмножини простору станів, яка називається атрактором. Наявність та поведінка атракторів дає інтуїтивне уявлення про досліджувану динамічну систему.\n\nОдже, згідно Такенсу, ідея полягає в тому, щоб на основі одиничних вимірювань системи, отримати $m$-розмірні реконструйовані часові вкладення\n\n$$\n\\vec{y}_i = \\left( y_i, y_{i+\\tau}, ... , y_{i+(m-1)\\tau} \\right),\n$$ {#eq-2-1}\n\nде $i$ проходить в діапазоні $1,..., N-(m-1)\\tau$; значення $\\tau$ представляє часову затримку, а $m$ --- це розмірність вкладень (кількість змінних, що включає кожна траєкторія).\n\nКод для реконструкції фазового простору може виглядати наступним чином:\n\nДля реконструкції фазового простору використовуватимемо метод `complexity_embedding()`. Його синтаксис виглядає наступним чином:\n\n**`complexity_embedding(signal, delay=1, dimension=3, show=False, **kwargs)`**\n\n**Параметри**\n\n- **signal** (*Union[list, np.array, pd.Series]*) --- сигнал (тобто часовий ряд) у вигляді вектора значень. Також може бути рядком, наприклад, `\"lorenz\"` (атрактор Лоренца), `\"rossler\"` (атрактор Росслера) або `\"clifford\"` (атрактор Кліффорда) для отримання попередньо визначеного атрактора.\n- **delay** (*int*) --- часова затримка (часто позначається $\\tau$ іноді називають запізненням). Ще розглянемо метод `complexity_delay()` для оцінки оптимального значення цього параметра.\n- **dimension** (*int*) --- розмірність вкладень ($m$, іноді позначається як $d$ або порядок). Далі звернемось до методу `complexity_dimension()`, щоб оцінити оптимальне значення для цього параметра.\n- **show** (*bool*) --- Побудувати графік реконструйованого атрактора.\n- **kwargs** --- інші аргументи, що передаються до `complexity_attractor()`.\n\n**Повертає**\n\n- *array* --- реконструйований атрактор розміру `length - (dimension - 1) * delay`\n\n\n\nДалі імпортуємо необхідні для подальшої роботи модулі\n\nІ виконаємо налаштування рисунків для виводу\n\nТепер розглянемо можливість використання методу часових затримок і отриманих в подальшому атракторів у якості індикатора складності. Як і в попередній роботі, для прикладу завантажимо часовий ряд Біткоїна за період з 1 вересня 2015 по 1 березня 2020, використовуючи `yfinance`:\n\n::: {.callout-warning}\n## Увага\n\nВиконайте цей блок, якщо хочете зчитати дані не з Yahoo! Finance, а з власного файлу\n\n:::\n\n---\n\n---\n\nСпочатку оберемо вид ряду:\n1. вихідний ряд\n2. детермінований (різниця між теперішнім та попереднім значенням)\n3. прибутковості звичайні\n4. стандартизовані прибутковості\n5. абсолютні значення (волатильності)\n6. стандартизований ряд\n\nДля подальших розрахунків накращим варіантом буде вибір стандартизованого вихідного ряду або прибутковостей, оскільки значення вихідного часового ряду відрізняються на декілька порядків, і можуть сильно перевищувати встановлений параметр $\\varepsilon$. Тобто, для вихідних значень, що сильно різняться між собою, увесь часовий діапазон буде розглядатися як нерекурентний.\n\nСпочатку визначимо функції для виконання перетворення ряду:\n\nі тепер виконаємо перетворення, використовуючи дану функцію:\n\nОскільки ми не матимемо змоги візуалізувати багатовимірний фазовий простір ($m>3$), ми послуговуватимемось значеннями $m=2$ та $m=3$. Значення $\\tau$ будемо варіювати як із власних переконань, так і з опорою на функціонал бібліотеки `neuralkit2`. \n\nСкористаємось методом `complexity_simulate()` для генерації різних тестових сигналів. \n\nУ зазначених вище прикладах прикладах ми обирали параметри $m$ і $\\tau$ згідно нашим власним міркуванням. Але, як правило, при виконанні серйозного дослідження, що матиме прикладне застосування, лише власних переконань буває недостатньо. У нашому випадку бажано було б, щоб зазначені параметри обирались автоматично, опираючись на конкретну статистичну процедуру. Бібліотека `neurokit2` представляє функціонал для автоматичного підбору параметрів розмірності та часової затримки. Коротко їх опишемо. \n\n### Автоматизований підбір параметра часової затримки, $\\tau$\n\nЧасова затримка (*Tau* $\\tau$ також відома як *Lag*) є одним з двох критичних параметрів, що беруть участь у процедурі реконструкції фазового простору. Він відповідає затримці у відліках між вихідним сигналом і його затриманою версією (версіями). Іншими словами, скільки відліків ми розглядаємо між певним станом сигналу та його найближчим минулим станом.\n\nЯкщо $\\tau$ менше оптимального теоретичного значення, послідовні координати стану системи корельовані і атрактор недостатньо розгорнутий. І навпаки, коли $\\tau$ більше, ніж повинно бути, послідовні координати майже незалежні, що призводить до некорельованої та неструктурованої хмари точок.\n\nВибір параметрів *затримки* та *розмірності* представляє нетривіальну задачу. Один з підходів полягає у їх (напів)незалежному виборі (оскільки вибір розмірності часто вимагає затримки) за допомогою функцій `complexity_delay()` та `complexity_dimension()`. Однак, існують методи спільного оцінювання, які намагаються знайти оптимальну затримку та розмірність одночасно.\n\nЗауважте також, що деякі автори (наприклад, Розенштейн, 1994) пропонують спочатку визначити оптимальну розмірність вбудовування, а потім розглядати оптимальне значення затримки як оптимальну затримку між першою та останньою координатами затримки (іншими словами, фактична затримка має дорівнювати оптимальній затримці, поділеній на оптимальну розмірність вбудовування мінус 1).\n\nДекілька авторів запропонували різні методи для вибору затримки:\n\n- **Фрейзер і Свінні (1986)** пропонують використовувати перший локальний мінімум взаємної інформації між затриманим і незатриманим часовими рядами, ефективно визначаючи значення $\\tau$, для якого вони діляться найменшою інформацією (і де атрактор є найменш надлишковим). На відміну від автокореляції, взаємна інформація враховує також нелінійні кореляції.\n- **Тейлер (1990)** запропонував вибирати таке значення $\\tau$, при якому автокореляція між сигналом та його зміщенною версією при $\\tau$ вперше перетинає значення $1/\\exp$. Методи, що базуються на автокореляції, мають перевагу в короткому часі обчислень, коли вони обчислюються за допомогою алгоритму швидкого перетворення Фур'є (fast Fourier transform, FFT).\n- **Касдаглі (1991)** пропонує замість цього брати перший нульовий перетин автокореляції.\n- **Розенштейн (1993)** пропонує апроксимувати точку, де функція автокореляцій падає до $\\left( 1-1/\\exp \\right)$ від свого максимального значення.\n- **Розенштейн (1994)** пропонує наближатися до точки, близької до 40% нахилу середнього зміщення від діагоналі.\n- **Кім (1999)** пропонує оцінювати Tau за допомогою кореляційного інтегралу, який називається C-C методом, і який, як виявилося, узгоджується з результатами, отриманими за допомогою методу взаємної інформації. Цей метод використовує статистику в реконструйованому фазовому просторі, а не аналізує часову еволюцію ряду. Однак час обчислень для цього методу значно довший через необхідність порівнювати кожну унікальну пару парних векторів у реконструйованому сигналі на кожну затримку.\n- **Лайл (2021)** описує \"Реконструкцію симетричного проекційного атрактора\" (Symmetric Projection Attractor Reconstruction, SPAR), де $1/3$ від домінуючої частоти (тобто довжини середнього \"циклу\") може бути підходящим значенням для приблизно періодичних даних, і робить атрактор чутливим до морфологічних змін. Див. також [доповідь Астона](https://youtu.be/GGrOJtcTcHA?t=730). Цей метод також є найшвидшим, але може не підходити для аперіодичних сигналів. Аргумент `algorithm` (за замовчуванням `\"fft\"`) передається до аргументу `method` методу [`signal_psd()`](https://neuropsychology.github.io/NeuroKit/functions/signal.html#signal-psd).\n\nМожна також зазначити наступний метод для об'єднаного підбору параметрів затримки та розмірності:\n\n- **Гаутама (2003)** зазначає, що на практиці часто використовують фіксовану часову затримку і відповідно регулюють розмірність вбудовування. Оскільки це може призвести до великих значень $m$ (а отже, до вкладених даних великого розміру) і, відповідно, до повільної обробки, вони описують метод оптимізації для спільного визначення $m$ і $\\tau$ на основі показника **entropy ratio**.\n\nРозглянемо оптимальні значення розмірності та затримки для часового сигналу Біткоїна:\n\n@fig-btc-delay-fraser1986 показує, що перший локальний мінімум взаємної інформації для стандартизованих вихідних значень Біткоїна знаходиться на 273 лагу. Для візуального огляду реконструйованого атрактора це значення, можливо, є найбільш адекватним. Але використовуючи настільки велику часову затримку, ми втрачаємо доволі багато проміжних значень, що також можуть містити досить важливу приховану інформацію для кількісних розрахунків. \n\n@fig-btc-delay-theiler демонструє, що автокореляція між стандартизованих вихідним сигналом Біткоїна та його зміщенною версією при $\\tau=195$ вперше перетинає значення $1/\\exp$. Бачимо, що дане значення затримки є трохи меншим за те, що було отримано до цього, але суті це не змінює. Також бачимо, що між реконструйованими атракторами для $\\tau=195$ та $\\tau=273$ немає кардинальної візуальної різниці. \n\nЯк можна бачити по прикладу вище, не всі методи надають адекватну оцінку розмірності нашого сигналу. Спробуємо привести вихідні значення Біткоїна до прибутковостей та повторити процедуру Касдаглі ще раз.  \n\nЦього разу нам вдалося досягти оптимального результату, але приклад вище демонструє, що кожна процедура має свої виключення. @fig-btc-delay-casdagli1991 показує, що значення прибутковостей Біткоїна характеризуються певними кореляціями лише на перших 4-ох лагах. Подальші часові зміщення роблять значення прибутковостей незалежними один від одного.\n\n@fig-btc-delay-rosenstein1993 демонструє, що при $\\tau=101$ функція автокореляцій перетинає значення $\\left( 1-1/\\exp \\right)$. При цьому видно, що навіть для такого лагу зберігається значна частка кореляцій між стандартизованими вихідними значеннями Біткоїна. \n\nРисунок вище показує, що при $\\tau=120$ зміщення реконструйованих траєкторій від їх оригінального положення на лінії ідентичності зберігає найбільшу кількість інформації стосовно атрактора стандартизованих значень Біткоїна. \n\nЗгідно представленого вище результату найбільш значущі частоти, отримані за допомогою перетворення Фур'є, зберігаються при $\\tau=109$. \n\nТепер подивимось як це виглядатиме для об'єднаного підбору параметрів\n\nОскільки представлена вище процедура є доволі громіздкою в плані обчислювальних потужностей, ми обрали діапазон $\\tau$ в межах від 1 до 30. Видно, що при $\\tau$ близької до 10 оптимальне значення розмірності атрактора дорівнює 20. Можливо, при значеннях $\\tau$ близьких до 100 або 200, ми могли б отримати зовсім інше значення розмірності, але це потребує додаткових експериментів. \n\n### Автоматизований підбір параметра розмірності вкладень, $m$\n\nЗа дану процедуру відповідає метод `complexity dimension()`. Її синтаксис виглядає наступним чином:\n\n**`complexity_dimension(signal, delay=1, dimension_max=20, method='afnn', show=False, **kwargs)`**\n\nХоча зазвичай використовують $m=2$ або $m=3$, але різні автори пропонують наступні процедури підбору:\n\n- **Кореляційна розмірність (Correlation Dimension, CD)**: Одним з перших методів оцінки оптимального $m$ був розрахунок кореляційної розмірності для вкладень різного розміру і пошук насичення (тобто плато) в її значенні при збільшенні розміру векторів. Одне з обмежень полягає в тому, що насичення буде також мати місце, коли даних недостатньо для адекватного заповнення простору високої розмірності (зауважте, що в загальному випадку не рекомендується мати настільки великі вкладення, оскільки це значно скорочує довжину сигналу).\n- **Найближчі хибні сусіди (False Nearest Neighbour, FNN)**: Метод, запропонований Кеннелом та ін., базується на припущенні, що дві точки, які є близькими одна до одної в достатній розмірності вбудовування, повинні залишатися близькими при збільшенні розмірності. Алгоритм перевіряє сусідів при збільшенні розмірності вкладень, поки не знайде лише незначну кількість хибних сусідів при переході від розмірності $m$ до $m+1$. Це відповідає найнижчій розмірності вкладення, яка, як передбачається, дає розгорнуту реконструкцію просторово-часового стану. Цей метод може не спрацювати в зашумлених сигналах через марну спробу розгорнути шум (а в чисто випадкових сигналах кількість хибних сусідів суттєво не зменшується зі збільшенням $m$). На рисунку нижче показано, як проекції на простори більшої розмірності можна використовувати для виявлення хибних найближчих сусідів. Наприклад, червона та жовта точки є сусідами в одновимірному просторі, але не в двовимірному.\n\n![](Images\\lab_2\\douglas2022b.png){width=30% fig-align=\"center\" fig-alt=\"Проєкція траєкторій до різних розмірностей\"}\n\n- **Середні хибні сусіди (Average False Neighbors, AFN)**: Ця модифікація методу FNN, розроблена Сао (1997), усуває один з його основних недоліків --- необхідність евристичного вибору порогових значень $r$. Метод використовує максимальну евклідову відстань для представлення найближчих сусідів і усереднює всі відношення відстані в $m+1$ розмірності до розмірності $m$ і визначає *E1* та *E2* як параметри. Оптимальна розмірність відповідає досягається тоді, коли *E1* перестає змінюватися (досягає плато). *E1* досягає плато при розмірності *d0*, якщо сигнал надходить від атрактора. Тоді *d0*+1* є оптимальною мінімальною розмірністю вкладення. *E2* є корисною величиною для того, щоб відрізнити детерміновані сигнали від стохастичних. Константа *E2*, що близька до 1 для будь-якої розмірності вкладень $d$, вказує на випадковість даних, оскільки майбутні значення не залежать від минулих значень.\n\n**Параметри**\n\n- **signal** (*Union[list, np.array, pd.Series]*) --- сигнал (тобто часовий ряд) у вигляді вектора значень.\n- **delay** (*int*) --- часова затримка у відліках. Для вибору оптимального значення цього параметра ми ще скористаємось методом `complexity_delay()`.\n- **dimension_max** (*int*) --- максимальний розмір вкладення для тестування.\n- **method** (*str*) --- Може бути `\"afn\"` (середні хибні сусіди), `\"fnn\"` (найближчий хибний сусід) або `\"cd\"` (кореляційна розмірність).\n- **show** (*bool*) --- Візуалізувати результат.\n- **kwargs** --- інші аргументи, такі як $R=10.0$ або $A=2.0$ (відносне та абсолютне граничне значення, тільки для методу `\"fnn\"`).\n\n**Повертає**\n\n- **dimension** (*int*) --- оптимальна розмірність вкладень.\n- **parameters** (*dict*) --- словник python, що містить додаткову інформацію про параметри, які використовуються для обчислення оптимальної розмірності.\n\nСпробуємо отримати оптимальне значення розмірності згідно зазначених процедур. В якості часової затримки можна взять $\\tau=100$. Приблизно таке значення спостерігалося для кожної процедури. \n\n@fig-btc-dim-cd представляє, що оптимальна розмірність вкладень при якій досягається найбільш інформативна репрезентація фазового простору дорівнює 7.  \n\nЗ представленого вище рисунку видно, що найнижча розмірності вкладення, яка, як передбачається, дає розгорнуту реконструкцію просторово-часового стану, дорівнює 3. Саме при переході від 3-ох вимірного фазового простору до 4-ох вимірного ми бачимо, що кількість хибних сусідів стає мінімальною і далі не наростає. \n\nАлгоритм середніх хибних сусідів показує, що тут розмірність вкладень $m=5$ є найоптимальнішою. При подальшому наростанні розмірності, атрактор має походити на більш стохастичний, що вказує на втрату всіх кореляцій, що могли бути присутні в досліджуваному сигналі.  \n\nЗгідно з представленими вище алгоритмами автоматичного підбору, розмірність вкладень можна обирати в діапазоні значень від 3 до 7. Тепер на основі отриманих результатів приступимо до побудови рекурентної діаграми. \n\n### Побудова рекурентної матриці\n\nЯк вже зазначалося, рекурентний аналіз кількісно визначає кількість і тривалість рекурентних станів динамічної системи, що визначаються на основі реконструйованих траєкторій фазового простору. \n\nМи маємо змогу побудувати рекурентну матрицю, використовуючи метод `recurrence_matrix()`. \n\nЙого синтаксис виглядає наступним чином:\n\n**`recurrence_matrix(signal, delay=1, dimension=3, tolerance='default', show=False)`**\n\n**Параметри**\n\n- **signal** (*Union[list, np.ndarray, pd.Series]*) --- сигнал (тобто часовий ряд) у вигляді вектора значень.\n- **delay** (*int*) --- затримка в часі. \n- **dimension** (*int*) --- розмірність вкладень, $m$. \n- **tolerance** (*float*) --- радіус $\\varepsilon$ багатовимірного околу в межах якого шукаються рекурентні траєкторії (часто позначається як $r$), відстань, на якій дві точки даних вважаються схожими. Якщо `\"sd\"` (за замовчуванням), буде встановлено значення $0.2 \\cdot SD_{signal}$. Емпіричним правилом є встановлення $r$ таким чином, щоб відсоток точок, класифікованих як рекурентні, становив приблизно 2-5%.\n- **show** (*bool*) --- візуалізувати рекурентну матрицю.\n\n**Повертає**\n\n- *np.ndarray* --- рекурентну матрицю.\n- *np.ndarray* --- матрицю відстаней.\n\nПобудуємо рекурентну матрицю для вихідних значень Біткоїна, його прибутковостей та стандартизованого вихідного ряду. Розмірність $m=4$, часова затримка $\\tau=1$, радіус $\\varepsilon=0.3$. \n\nЯк можна бачити з представленого рисунку всі траєкторії залишаються доволі віддаленими один від одного, ніякої рекурентності тут не передбачається. \n\nТепер спробуємо подивитися на стандартизовані прибутковості.\n\nТепер можемо бачити, що Біткоїн став характризуватися чорними смугами, що відображають динаміку певних детермінованих процесів. У той же час білі смуги характеризують періоди абсолютно аномальної (непередбачуваної поведінки на даному ринку). Видно, що прибутковості залишаються доволі некорельованими, про що і свідчить переважне домінування саме білих областей.\n\nСпробуємо тепер подивитись на стандартизований вихідний ряд.\n\nНа початку свого існування Біткоїн характеризувався доволі високим ступенем передбачуваності, меншої волатильності власних коливань. Надалі почали предомінувати білі області, але видно, що тепер Біткоїну властива динаміка подібна до броунівсього руху. \n\n## Завдання для самостійної роботи\n\n1. Отримати індекс часового ряду у викладача\n2. Провести дослідження його рекурентних властивостей згідно інструкції\n3. Порівняти фазові портрети і рекурентні діаграми для стандартизованого вихідного ряду та прибутковостей. Що спільного між ними і чим вони відрізняються?\n4. Зробити висновки\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"highlight-style":"oblivion","css":["style.css"],"output-file":"lab_2.html"},"language":{"toc-title-document":"Зміст","toc-title-website":"На цій сторінці","related-formats-title":"Другие форматы","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Источник","section-title-abstract":"Анотація","section-title-appendices":"Додатки","section-title-footnotes":"Зноски","section-title-references":"Використана література","section-title-reuse":"Повторне використання","section-title-copyright":"Авторские права","section-title-citation":"Цитата","appendix-attribution-cite-as":"Будь-ласка, цитуйте цю роботу як:","appendix-attribution-bibtex":"BibTeX:","title-block-author-single":"Автор","title-block-author-plural":"Автори","title-block-affiliation-single":"Приналежність","title-block-affiliation-plural":"Приналежності","title-block-published":"Дата публікації","title-block-modified":"Змінено","callout-tip-title":"Совет","callout-note-title":"Уведомление","callout-warning-title":"Предупреждение","callout-important-title":"Важное уведомление","callout-caution-title":"Осторожность","code-summary":"Код","code-tools-menu-caption":"Код","code-tools-show-all-code":"Розгорнути код","code-tools-hide-all-code":"Приховати код","code-tools-view-source":"Переглянути код","code-tools-source-code":"Вихідний код","code-line":"Линия","code-lines":"Линии","copy-button-tooltip":"Копіювати","copy-button-tooltip-success":"Скопійовано!","repo-action-links-edit":"Редагувати сторінку","repo-action-links-source":"Переглянути код","repo-action-links-issue":"Повідомити про проблему","back-to-top":"Наверх","search-no-results-text":"Пошук не дав результату","search-matching-documents-text":"Результати пошуку","search-copy-link-title":"Скопіюйте посилання для пошуку","search-hide-matches-text":"Приховати додаткові результати","search-more-match-text":"Додатковий результат у цьому документі","search-more-matches-text":"Додаткові результати у цьому документі","search-clear-button-title":"Очистити","search-detached-cancel-button-title":"Скасувати","search-submit-button-title":"Надіслати","search-label":"Поиск","toggle-section":"Переключить раздел","toggle-sidebar":"Переключить боковую панель навигации","toggle-dark-mode":"Переключить темный режим","toggle-reader-mode":"Переключить режим чтения","toggle-navigation":"Переключить навигацию","crossref-fig-title":"Рис.","crossref-tbl-title":"Таблиця","crossref-lst-title":"Список","crossref-thm-title":"Теорема","crossref-lem-title":"Лема","crossref-cor-title":"Наслідок","crossref-prp-title":"Твердження","crossref-cnj-title":"Гіпотеза","crossref-def-title":"Визначення","crossref-exm-title":"Приклад","crossref-exr-title":"Завдання","crossref-ch-prefix":"Глава","crossref-apx-prefix":"Додаток","crossref-sec-prefix":"Розділ","crossref-eq-prefix":"Рівняння","crossref-lof-title":"Список Рисунків","crossref-lot-title":"Список Таблиць","crossref-lol-title":"Список Каталогів","environment-proof-title":"Доведення","environment-remark-title":"Зауваження","environment-solution-title":"Рішення","listing-page-order-by":"Сортувати по","listing-page-order-by-default":"попередньо вибраний","listing-page-order-by-date-asc":"Найновіші","listing-page-order-by-date-desc":"Найстріші","listing-page-order-by-number-desc":"За спаданням","listing-page-order-by-number-asc":"За зростанням","listing-page-field-date":"Дата","listing-page-field-title":"Заголовок","listing-page-field-description":"Опис","listing-page-field-author":"Автор","listing-page-field-filename":"Ім'я файлу","listing-page-field-filemodified":"Змінено","listing-page-field-subtitle":"Підзаголовок","listing-page-field-readingtime":"Час читання","listing-page-field-categories":"Категорії","listing-page-minutes-compact":"{0} хвилин","listing-page-category-all":"Все","listing-page-no-matches":"Немає відповідних елементів"},"metadata":{"lang":"ru","fig-responsive":true,"quarto-version":"1.3.433","bibliography":["references.bib"],"callout-appearance":"default","page-layout":"full","theme":{"light":"cosmo","dark":"superhero"},"title":"Лабораторна робота № 2"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":true,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","toc":true,"number-sections":true,"output-file":"lab_2.pdf"},"language":{"toc-title-document":"Зміст","toc-title-website":"На цій сторінці","related-formats-title":"Другие форматы","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Источник","section-title-abstract":"Анотація","section-title-appendices":"Додатки","section-title-footnotes":"Зноски","section-title-references":"Використана література","section-title-reuse":"Повторне використання","section-title-copyright":"Авторские права","section-title-citation":"Цитата","appendix-attribution-cite-as":"Будь-ласка, цитуйте цю роботу як:","appendix-attribution-bibtex":"BibTeX:","title-block-author-single":"Автор","title-block-author-plural":"Автори","title-block-affiliation-single":"Приналежність","title-block-affiliation-plural":"Приналежності","title-block-published":"Дата публікації","title-block-modified":"Змінено","callout-tip-title":"Совет","callout-note-title":"Уведомление","callout-warning-title":"Предупреждение","callout-important-title":"Важное уведомление","callout-caution-title":"Осторожность","code-summary":"Код","code-tools-menu-caption":"Код","code-tools-show-all-code":"Розгорнути код","code-tools-hide-all-code":"Приховати код","code-tools-view-source":"Переглянути код","code-tools-source-code":"Вихідний код","code-line":"Линия","code-lines":"Линии","copy-button-tooltip":"Копіювати","copy-button-tooltip-success":"Скопійовано!","repo-action-links-edit":"Редагувати сторінку","repo-action-links-source":"Переглянути код","repo-action-links-issue":"Повідомити про проблему","back-to-top":"Наверх","search-no-results-text":"Пошук не дав результату","search-matching-documents-text":"Результати пошуку","search-copy-link-title":"Скопіюйте посилання для пошуку","search-hide-matches-text":"Приховати додаткові результати","search-more-match-text":"Додатковий результат у цьому документі","search-more-matches-text":"Додаткові результати у цьому документі","search-clear-button-title":"Очистити","search-detached-cancel-button-title":"Скасувати","search-submit-button-title":"Надіслати","search-label":"Поиск","toggle-section":"Переключить раздел","toggle-sidebar":"Переключить боковую панель навигации","toggle-dark-mode":"Переключить темный режим","toggle-reader-mode":"Переключить режим чтения","toggle-navigation":"Переключить навигацию","crossref-fig-title":"Рис.","crossref-tbl-title":"Таблиця","crossref-lst-title":"Список","crossref-thm-title":"Теорема","crossref-lem-title":"Лема","crossref-cor-title":"Наслідок","crossref-prp-title":"Твердження","crossref-cnj-title":"Гіпотеза","crossref-def-title":"Визначення","crossref-exm-title":"Приклад","crossref-exr-title":"Завдання","crossref-ch-prefix":"Глава","crossref-apx-prefix":"Додаток","crossref-sec-prefix":"Розділ","crossref-eq-prefix":"Рівняння","crossref-lof-title":"Список Рисунків","crossref-lot-title":"Список Таблиць","crossref-lol-title":"Список Каталогів","environment-proof-title":"Доведення","environment-remark-title":"Зауваження","environment-solution-title":"Рішення","listing-page-order-by":"Сортувати по","listing-page-order-by-default":"попередньо вибраний","listing-page-order-by-date-asc":"Найновіші","listing-page-order-by-date-desc":"Найстріші","listing-page-order-by-number-desc":"За спаданням","listing-page-order-by-number-asc":"За зростанням","listing-page-field-date":"Дата","listing-page-field-title":"Заголовок","listing-page-field-description":"Опис","listing-page-field-author":"Автор","listing-page-field-filename":"Ім'я файлу","listing-page-field-filemodified":"Змінено","listing-page-field-subtitle":"Підзаголовок","listing-page-field-readingtime":"Час читання","listing-page-field-categories":"Категорії","listing-page-minutes-compact":"{0} хвилин","listing-page-category-all":"Все","listing-page-no-matches":"Немає відповідних елементів"},"metadata":{"block-headings":true,"lang":"ru","bibliography":["references.bib"],"callout-appearance":"default","documentclass":"report","title":"Лабораторна робота № 2"},"extensions":{"book":{"selfContainedOutput":true}}},"docx":{"identifier":{"display-name":"MS Word","target-format":"docx","base-format":"docx"},"execute":{"fig-width":5,"fig-height":4,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"docx","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"page-width":6.5},"pandoc":{"default-image-extension":"png","to":"docx","toc":true,"number-sections":true,"output-file":"lab_2.docx"},"language":{"toc-title-document":"Зміст","toc-title-website":"На цій сторінці","related-formats-title":"Другие форматы","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Источник","section-title-abstract":"Анотація","section-title-appendices":"Додатки","section-title-footnotes":"Зноски","section-title-references":"Використана література","section-title-reuse":"Повторне використання","section-title-copyright":"Авторские права","section-title-citation":"Цитата","appendix-attribution-cite-as":"Будь-ласка, цитуйте цю роботу як:","appendix-attribution-bibtex":"BibTeX:","title-block-author-single":"Автор","title-block-author-plural":"Автори","title-block-affiliation-single":"Приналежність","title-block-affiliation-plural":"Приналежності","title-block-published":"Дата публікації","title-block-modified":"Змінено","callout-tip-title":"Совет","callout-note-title":"Уведомление","callout-warning-title":"Предупреждение","callout-important-title":"Важное уведомление","callout-caution-title":"Осторожность","code-summary":"Код","code-tools-menu-caption":"Код","code-tools-show-all-code":"Розгорнути код","code-tools-hide-all-code":"Приховати код","code-tools-view-source":"Переглянути код","code-tools-source-code":"Вихідний код","code-line":"Линия","code-lines":"Линии","copy-button-tooltip":"Копіювати","copy-button-tooltip-success":"Скопійовано!","repo-action-links-edit":"Редагувати сторінку","repo-action-links-source":"Переглянути код","repo-action-links-issue":"Повідомити про проблему","back-to-top":"Наверх","search-no-results-text":"Пошук не дав результату","search-matching-documents-text":"Результати пошуку","search-copy-link-title":"Скопіюйте посилання для пошуку","search-hide-matches-text":"Приховати додаткові результати","search-more-match-text":"Додатковий результат у цьому документі","search-more-matches-text":"Додаткові результати у цьому документі","search-clear-button-title":"Очистити","search-detached-cancel-button-title":"Скасувати","search-submit-button-title":"Надіслати","search-label":"Поиск","toggle-section":"Переключить раздел","toggle-sidebar":"Переключить боковую панель навигации","toggle-dark-mode":"Переключить темный режим","toggle-reader-mode":"Переключить режим чтения","toggle-navigation":"Переключить навигацию","crossref-fig-title":"Рис.","crossref-tbl-title":"Таблиця","crossref-lst-title":"Список","crossref-thm-title":"Теорема","crossref-lem-title":"Лема","crossref-cor-title":"Наслідок","crossref-prp-title":"Твердження","crossref-cnj-title":"Гіпотеза","crossref-def-title":"Визначення","crossref-exm-title":"Приклад","crossref-exr-title":"Завдання","crossref-ch-prefix":"Глава","crossref-apx-prefix":"Додаток","crossref-sec-prefix":"Розділ","crossref-eq-prefix":"Рівняння","crossref-lof-title":"Список Рисунків","crossref-lot-title":"Список Таблиць","crossref-lol-title":"Список Каталогів","environment-proof-title":"Доведення","environment-remark-title":"Зауваження","environment-solution-title":"Рішення","listing-page-order-by":"Сортувати по","listing-page-order-by-default":"попередньо вибраний","listing-page-order-by-date-asc":"Найновіші","listing-page-order-by-date-desc":"Найстріші","listing-page-order-by-number-desc":"За спаданням","listing-page-order-by-number-asc":"За зростанням","listing-page-field-date":"Дата","listing-page-field-title":"Заголовок","listing-page-field-description":"Опис","listing-page-field-author":"Автор","listing-page-field-filename":"Ім'я файлу","listing-page-field-filemodified":"Змінено","listing-page-field-subtitle":"Підзаголовок","listing-page-field-readingtime":"Час читання","listing-page-field-categories":"Категорії","listing-page-minutes-compact":"{0} хвилин","listing-page-category-all":"Все","listing-page-no-matches":"Немає відповідних елементів"},"metadata":{"lang":"ru","bibliography":["references.bib"],"callout-appearance":"default","title":"Лабораторна робота № 2"},"extensions":{"book":{"selfContainedOutput":true}}},"epub":{"identifier":{"display-name":"ePub","target-format":"epub","base-format":"epub"},"execute":{"fig-width":5,"fig-height":4,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"epub","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":false,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"default-image-extension":"png","html-math-method":"mathml","to":"epub","toc":true,"number-sections":true,"output-file":"lab_2.epub"},"language":{"toc-title-document":"Зміст","toc-title-website":"На цій сторінці","related-formats-title":"Другие форматы","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Источник","section-title-abstract":"Анотація","section-title-appendices":"Додатки","section-title-footnotes":"Зноски","section-title-references":"Використана література","section-title-reuse":"Повторне використання","section-title-copyright":"Авторские права","section-title-citation":"Цитата","appendix-attribution-cite-as":"Будь-ласка, цитуйте цю роботу як:","appendix-attribution-bibtex":"BibTeX:","title-block-author-single":"Автор","title-block-author-plural":"Автори","title-block-affiliation-single":"Приналежність","title-block-affiliation-plural":"Приналежності","title-block-published":"Дата публікації","title-block-modified":"Змінено","callout-tip-title":"Совет","callout-note-title":"Уведомление","callout-warning-title":"Предупреждение","callout-important-title":"Важное уведомление","callout-caution-title":"Осторожность","code-summary":"Код","code-tools-menu-caption":"Код","code-tools-show-all-code":"Розгорнути код","code-tools-hide-all-code":"Приховати код","code-tools-view-source":"Переглянути код","code-tools-source-code":"Вихідний код","code-line":"Линия","code-lines":"Линии","copy-button-tooltip":"Копіювати","copy-button-tooltip-success":"Скопійовано!","repo-action-links-edit":"Редагувати сторінку","repo-action-links-source":"Переглянути код","repo-action-links-issue":"Повідомити про проблему","back-to-top":"Наверх","search-no-results-text":"Пошук не дав результату","search-matching-documents-text":"Результати пошуку","search-copy-link-title":"Скопіюйте посилання для пошуку","search-hide-matches-text":"Приховати додаткові результати","search-more-match-text":"Додатковий результат у цьому документі","search-more-matches-text":"Додаткові результати у цьому документі","search-clear-button-title":"Очистити","search-detached-cancel-button-title":"Скасувати","search-submit-button-title":"Надіслати","search-label":"Поиск","toggle-section":"Переключить раздел","toggle-sidebar":"Переключить боковую панель навигации","toggle-dark-mode":"Переключить темный режим","toggle-reader-mode":"Переключить режим чтения","toggle-navigation":"Переключить навигацию","crossref-fig-title":"Рис.","crossref-tbl-title":"Таблиця","crossref-lst-title":"Список","crossref-thm-title":"Теорема","crossref-lem-title":"Лема","crossref-cor-title":"Наслідок","crossref-prp-title":"Твердження","crossref-cnj-title":"Гіпотеза","crossref-def-title":"Визначення","crossref-exm-title":"Приклад","crossref-exr-title":"Завдання","crossref-ch-prefix":"Глава","crossref-apx-prefix":"Додаток","crossref-sec-prefix":"Розділ","crossref-eq-prefix":"Рівняння","crossref-lof-title":"Список Рисунків","crossref-lot-title":"Список Таблиць","crossref-lol-title":"Список Каталогів","environment-proof-title":"Доведення","environment-remark-title":"Зауваження","environment-solution-title":"Рішення","listing-page-order-by":"Сортувати по","listing-page-order-by-default":"попередньо вибраний","listing-page-order-by-date-asc":"Найновіші","listing-page-order-by-date-desc":"Найстріші","listing-page-order-by-number-desc":"За спаданням","listing-page-order-by-number-asc":"За зростанням","listing-page-field-date":"Дата","listing-page-field-title":"Заголовок","listing-page-field-description":"Опис","listing-page-field-author":"Автор","listing-page-field-filename":"Ім'я файлу","listing-page-field-filemodified":"Змінено","listing-page-field-subtitle":"Підзаголовок","listing-page-field-readingtime":"Час читання","listing-page-field-categories":"Категорії","listing-page-minutes-compact":"{0} хвилин","listing-page-category-all":"Все","listing-page-no-matches":"Немає відповідних елементів"},"metadata":{"lang":"ru","bibliography":["references.bib"],"callout-appearance":"default","title":"Лабораторна робота № 2"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf","docx","epub"]}